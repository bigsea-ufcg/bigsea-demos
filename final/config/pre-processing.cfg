[manager]
ip = 10.11.4.205
port = 1514
plugin = sahara
cluster_size = 1 
flavor_id = d7210ff1-301f-4f19-a36d-fda723eb27a4 
image_id = 40e580d1-873a-4e7b-9147-fca9750db9e1 
bigsea_username = testuser
bigsea_password = aB123456

[plugin]
opportunistic = False
args = <btr-input-path> <btr-pre-processing-output-folder> 
dependencies = com.databricks:spark-csv_2.10:1.5.0 
main_class = 
job_template_name = Pre-Processing
job_binary_name = Pre-Processing
job_binary_url = hdfs://10.11.4.225/user/ubuntu/wp3-demo/src/data-preprocessing.py
input_ds_id = 
output_ds_id = 
plugin_app = spark_progress
expected_time = 800
percentage = 50
number_of_jobs = 5 
collect_period = 5 
openstack_plugin = spark
plugin_version = 2.1.0
job_type = Spark
cluster_id = 
master_ng = cdc88bac-c0ac-44b3-8605-45d0df3b6cd2 
slave_ng = ccc523ee-d5a4-41f7-8932-d0f0b97d8394
opportunistic_slave_ng = ccc523ee-d5a4-41f7-8932-d0f0b97d8394
net_id = 64ee4355-4d7f-4170-80b4-5e8348af6a61
app_name = bulma
days = 10

[scaler]
starting_cap = 80
scaler_plugin = progress-error
actuator = kvm
metric_source = monasca
application_type = os_generic
check_interval = 10
trigger_down = 10
trigger_up = 10
min_cap = 20
max_cap = 100
actuation_size = 15
metric_rounding = 2 
